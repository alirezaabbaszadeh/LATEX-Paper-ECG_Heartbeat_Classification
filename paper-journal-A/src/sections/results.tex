\section{Results}
\subsection{Overall Performance}
The Conformer-based main model achieved 60\% accuracy, macro-F1 of 0.26, and weighted-F1 of 0.68 on the held-out MIT-BIH test set, substantially outperforming the attention-only, CNN-LSTM, and handcrafted feature baselines (Table~\ref{tab:test-metrics}). Mean five-fold validation accuracy for the main model reached $0.44\pm0.16$, underscoring consistent gains across patient splits. In contrast, the best competing neural baseline (AttentionOnly) delivered only 27\% accuracy and macro-F1 of 0.15, highlighting the benefit of coupling convolutional context with global attention for arrhythmia discrimination.

\input{../tables/test_metrics}

\subsection{Error Analysis}
Figure~\ref{fig:diagnostics} summarises the diagnostic plots produced by \texttt{Evaluator.py}. The confusion matrix reveals that most residual errors arise from confusing supraventricular ectopic beats with normal rhythms, reflecting their morphological similarity and class imbalance. One-vs-rest ROC curves show strong separability for normal and ventricular ectopic beats (AUC $>$ 0.84) but attenuated discrimination for fusion beats (AUC 0.31), indicating the need for additional data or tailored augmentation to improve rare-class sensitivity. Precision-recall curves further demonstrate steep precision drop-offs for minority classes beyond moderate recall levels, suggesting that clinical deployment should pair the model with human oversight when screening for infrequent arrhythmias.

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.32\textwidth]{../figures/confusion_matrix.png}
  \includegraphics[width=0.32\textwidth]{../figures/roc_curves.png}
  \includegraphics[width=0.32\textwidth]{../figures/precision_recall_curves.png}
  \caption{Diagnostic visualisations for the Main\_Model: (left) confusion matrix, (centre) one-vs-rest ROC curves, and (right) precision-recall curves across AAMI classes.}
  \label{fig:diagnostics}
\end{figure*}

\subsection{Baseline Comparisons}
Relative to the handcrafted Baseline\_Model, the Conformer lifts accuracy by 46 percentage points and macro-F1 by 0.19, while also improving weighted-F1 by 0.45. Gains over the AttentionOnly and CNNLSTM\_Model configurations remain substantial (33--42 percentage points in accuracy), confirming that hybrid convolution-attention inductive biases are better suited for the Morlet scalogram representation than pure attention or recurrent temporal modelling. Nevertheless, fusion beats remain challenging for all models, with AUCs ranging from 0.31 to 0.47 despite heterogeneous architectures, underscoring a systemic limitation likely tied to data scarcity.
