\textbf{Background:} Timely interpretation of electrocardiograms is constrained by expert availability, motivating robust automated arrhythmia classification systems for clinical monitoring. \textbf{Methods:} We assembled 48 hours of MIT-BIH Arrhythmia data, augmented it with noise-aware signal synthesis, and trained a hybrid transformer-convolutional network with self-supervised contrastive pretraining on 1.2 million unlabeled beats. Performance was evaluated with stratified five-fold cross-validation and independent external validation on the INCART database. \textbf{Results:} The proposed model achieved a mean F1-score of 0.94 for the AAMI-recommended heartbeat categories, outperforming a tuned ResNet baseline by 4.8 percentage points and reducing false ventricular ectopy alarms by 31\%. External validation yielded an F1-score of 0.91 without recalibration, and ablation studies confirmed that self-supervision accounted for 60\% of the gains while attention-based channel reweighting preserved accuracy under 25 dB motion noise. \textbf{Conclusions:} Hybrid sequence models that combine transformer attention with convolutional feature extractors deliver clinically relevant accuracy improvements for arrhythmia monitoring and maintain robustness when labeled data are limited. Future work will integrate personalized calibration and prospective ward trials to assess workflow impact.
